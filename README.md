# Alphabet-Sign-Language-Recognition-using-Deep-Learning

This project focuses on training a deep learning model to interpret American Sign Language (ASL) alphabets through image recognition. The model aims to classify 200x200-pixel images into 29 classes, including the 26 letters of the English alphabet (A-Z), along with representations for SPACE, DELETE, and NOTHING gestures.

Dataset Overview

The dataset comprises:

Training Set: 87,000 images

200x200 pixels

Divided into 29 classes:

26 classes for the letters A-Z

3 classes for SPACE, DELETE, and NOTHING

Test Set: 29 images, intended for real-world testing and evaluation

Model Development

The objective of this project is to develop a deep learning model capable of accurately recognizing and classifying ASL alphabet signs. The model is trained on the provided dataset using machine learning techniques.
